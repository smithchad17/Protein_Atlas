{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook forked from https://www.kaggle.com/hiteshkumars/mmdetection-for-segmentation-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm #adds progress bar\n",
    "import pickle\n",
    "from itertools import groupby\n",
    "from pycocotools import mask as mutils\n",
    "from pycocotools import _mask as coco_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import base64 #converts binary to ASCII characters\n",
    "import typing as t #annotates functions like linter\n",
    "import zlib #compresses files\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"v4\"\n",
    "conf_name = \"mask_rcnn_s101_fpn_syncbn-backbone+head_mstrain_1x_coco\"\n",
    "model_name = 'mask_rcnn_resnest101_v5_ep9'\n",
    "ROOT = '/home/chad/GitHub/Protein_Atlas/'\n",
    "train_or_test = 'test'\n",
    "df = pd.read_csv(os.path.join(ROOT, 'input/sample_submission.csv'))\n",
    "if len(df) == 559:\n",
    "    debug = True\n",
    "    df = df[:3] #Subset rows 0 - 2\n",
    "else:\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ID  ImageWidth  ImageHeight  \\\n",
      "0  0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
      "1  004a270d-34a2-4d60-bbe4-365fca868193        2048         2048   \n",
      "2  00537262-883c-4b37-a3a1-a4931b6faea5        2048         2048   \n",
      "\n",
      "           PredictionString  \n",
      "0  0 1 eNoLCAgIMAEABJkBdQ==  \n",
      "1  0 1 eNoLCAgIMAEABJkBdQ==  \n",
      "2  0 1 eNoLCAgIMAEABJkBdQ==  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The '->' at the end of the function is function annotation. \n",
    "#The typing package interprets the meaning of the function\n",
    "\n",
    "#The same goes for the input. It is just saying it takes a 'mask' that is an np.ndarray.\n",
    "#t.Text is the output of the function. \n",
    "\n",
    "#COCO is a large-scale object detection, segmentation, and captioning dataset. Its API\n",
    "# has masking tools. https://cocodataset.org/#home\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "  \"\"\"Converts a binary mask into OID (OpenImage?) challenge encoding ascii text.\"\"\"\n",
    "\n",
    "  # check input mask --\n",
    "  if mask.dtype != np.bool:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "        mask.dtype)\n",
    "\n",
    "  mask = np.squeeze(mask)\n",
    "  if len(mask.shape) != 2:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "\n",
    "  # convert input mask to expected COCO API input --\n",
    "  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "  mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "  mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "  # RLE encode mask --\n",
    "  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "  # compress and base64 encoding -- Encodes binary data to printable ASCII characters\n",
    "  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "  base64_str = base64.b64encode(binary_str)\n",
    "  return base64_str.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/typing_text.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assert raises AssertionError is value is False. Used for debugging\n",
    "\n",
    "#cv2.IMREAD_UNCHANGED returns image as-is with alpha channel\n",
    "\n",
    "#Change image to 'uint8' to keep values in 0-255 range.\n",
    "\n",
    "def read_img(image_id, color, train_or_test='train', image_size=None):\n",
    "    filename = f'{ROOT}/input/{train_or_test}/{image_id}_{color}.png'\n",
    "    assert os.path.exists(filename), f'not found {filename}'\n",
    "    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    if image_size is not None:\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "    if img.dtype == 'uint16':\n",
    "        img = (img/256).astype('uint8') \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I believe the (1,2,0) for the transpose function is the order. \n",
    "# It might mean change to green, blue, red but not sure why yet. \n",
    "\n",
    "def load_RGBY_image(image_id, train_or_test='train', image_size=None):\n",
    "    red = read_img(image_id, \"red\", train_or_test, image_size)\n",
    "    green = read_img(image_id, \"green\", train_or_test, image_size)\n",
    "    blue = read_img(image_id, \"blue\", train_or_test, image_size)\n",
    "    # using rgb only here\n",
    "    #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n",
    "    stacked_images = np.transpose(np.array([red, green, blue]), (1,2,0))\n",
    "    return stacked_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_masked_img(image_id, mask):\n",
    "    img = load_RGBY_image(image_id, train_or_test)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask)\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask, alpha=0.6)\n",
    "    plt.title('Image + Mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate files for mmdetection\n",
    "\n",
    "MMDetection is an open source object detection toolbox based on PyTorch. It is a part of the OpenMMLab project developed by Multimedia Laboratory, CUHK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/coco_test_12510.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "out_image_dir = f'{ROOT}/output/mmdet_{exp_name}_{train_or_test}/'\n",
    "!mkdir -p {out_image_dir}\n",
    "\n",
    "annos = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "    image_id = df.iloc[idx].ID\n",
    "    img = load_RGBY_image(image_id, train_or_test)\n",
    "    \n",
    "    cv2.imwrite(f'{out_image_dir}/{image_id}.jpg', img)\n",
    "    ann = {\n",
    "        'filename': image_id+'.jpg',\n",
    "        'width': img.shape[1],\n",
    "        'height': img.shape[0],\n",
    "        'ann': {\n",
    "            'bboxes': None,\n",
    "            'labels': None,\n",
    "            'masks': None\n",
    "        }\n",
    "    }\n",
    "    annos.append(ann)\n",
    "    \n",
    "with open(f'{ROOT}pickle_tst.pkl', 'wb') as f:\n",
    "    pickle.dump(annos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
